#!/usr/bin/env perl
# PODNAME: load-rdf-dir
# ABSTRACT: Load RDF recursively from directory into Virtuoso database

use strict;
use warnings;
use feature qw(say signatures postderef);
no warnings qw(experimental::signatures experimental::postderef);

# NOTE Only using core modules inside of Docker.

if( $ENV{HARNESS_ACTIVE} ) {
	eval { require Test2::V0; Test2::V0->import; 1 } or die "Could not load Test2";
}

=head1 NAME

load-rdf-dir - Load RDF recursively from directory into Virtuoso database

=head1 DESCRIPTION

The following script goes through the directories recursively and loads them
into a Virtuoso Database. This is similar to how L<bulk loading|https://vos.openlinksw.com/owiki/wiki/VOS/VirtBulkRDFLoader>
works with Virtuoso already using C<ld_dir_all()>.

The main differences is that this script:

=over 4

=item *

Supports RDF HDT files by converting them to N-Triples;

=item *

TODO

Update graphs that change.

This is done by dropping any existing graph with a different checksum.

This could be done more efficiently with L<Delta-aware bulk loading of datasets
into Virtuoso|https://vos.openlinksw.com/owiki/wiki/VOS/VirtRDFBulkLoaderWithDelete>,
but this is not available with Virtuoso Open Source Edition (VOS).

=back


=cut

package Bio_Bricks::DB::Virtuoso {
	use strict;
	use warnings;
	use feature qw(signatures);
	no warnings qw(experimental::signatures);

	# CORE MODULES ONLY
	use File::Basename qw(basename dirname);
	use File::Find;
	use File::Spec;
	use IPC::Cmd qw(can_run); # can_run like File::Which, but core
	use File::Temp qw(tempfile);

=head1 NAME

Bio_Bricks::DB::Virtuoso

=cut

	# List from <https://vos.openlinksw.com/owiki/wiki/VOS/VirtBulkRDFLoader>:
	our %RDF_EXTS = (
		'.grdf' =>  'Geospatial RDF',
		'.nq'   =>  'N-Quads',
		'.nt'   =>  'N-Triples',
		'.owl'  =>  'OWL',
		'.rdf'  =>  'RDF/XML',
		'.trig' =>  'TriG',
		'.ttl'  =>  'Turtle',
		'.xml'  =>  'RDF/XML',
	);

	# NOTE: Inside of Docker:
	#
	#     $ which gzip bzip2 xz
	#     /usr/bin/gzip
	#     /usr/bin/bzip2
	our @COMPRESS_EXTS = qw( .gz .bz2 .xz );

	sub sql_escape_string($class, $x) { $x =~ s/'/''/gr; }
	sub sql_string($class, $x) { "'@{[ $class->sql_escape_string($x) ]}'"; }
	sub sql_null($class)       { 'NULL'; }

	my $rdf_exts_qr      = qr[ @{[ join '|', map quotemeta, keys %RDF_EXTS ]} ]x;
	my $quad_exts_qr     = qr[ @{[ join '|', map quotemeta, qw(.nq .trig) ]} ]x;
	my $compress_exts_qr = qr[ @{[ join '|', map quotemeta, @COMPRESS_EXTS ]} ]x;
	my $db_loadable_qr   = qr/
		$rdf_exts_qr
		$compress_exts_qr ?
		$
	/x;
	my $db_loadable_quad_qr   = qr/
		$quad_exts_qr
		$compress_exts_qr ?
		$
	/x;

=head1 CLASS METHODS

=head2 is_loadable_file

Returns boolean to indicate if a file is loadable by Virtuoso by its extension.
This includes compressed files.

=cut
	sub is_loadable_file($class, $rdf_file) {
		return !! ( -f $rdf_file && $rdf_file =~ $db_loadable_qr );
	}

=head2 is_loadable_quad_file

Returns boolean to indicate if a file is loadable by Virtuoso by its extension
and is a quad file. This includes compressed files.

=cut
	sub is_loadable_quad_file($class, $rdf_file) {
		return !! ( -f $rdf_file && $rdf_file =~ $db_loadable_quad_qr );
	}

=head2 map_single_file_to_graph_ld_dir

  $class->map_single_file_to_graph_ld_dir($file)

Returns the corresponding C<.graph> file for a given file just like
L<C<ld_dir>|(https://docs.openlinksw.com/virtuoso/fn_ld_dir/>.

If it is a file such as C<file.nt.gz>, it looks for C<file.nt.graph> or C<global.graph>.
If no C<.graph> file is found, returns C<undef>. If the file is a quad RDF, returns C<\undef>.

=cut
	sub map_single_file_to_graph_ld_dir($class, $file) {
		## no critic: Subroutines::ProhibitExplicitReturnUndef
		return unless -f $file;

		return \undef if $class->is_loadable_quad_file( $file );

		my $file_no_compress = $file =~ s/(?:$compress_exts_qr)$//r;
		my $file_graph = "${file_no_compress}.graph";

		return $file_graph if -f $file_graph;

		my $dir = dirname( $file );
		my $global_graph = File::Spec->catfile( $dir, 'global.graph' );

		return $global_graph if -f $global_graph;

		## no critic: Subroutines::ProhibitExplicitReturnUndef
		return undef;
	}

=head2 map_path_to_graph_files_ld_dir_all

  $class->map_path_to_graph_files_ld_dir_all($path)

For a given path, finds the corresponding graph files recursively
like L<C<ld_dir_all>|https://docs.openlinksw.com/virtuoso/fn_ld_dir_all/>.

Returns a C<HashRef> where keys are loadable files relative to C<$path>
and values are:

=over 4

=item * The C<.graph> file path relative to C<$path>.

=item * C<undef> if no such graph file is found.

=item * C<\undef> for quad files.

=back

=cut
	sub map_path_to_graph_files_ld_dir_all($class, $path) {
		my %path_to_graph_file;
		my %global_graph_by_dir;
		find( {
				wanted => sub {
					if( -d ) {
						my $global_for_dir = File::Spec->catfile($File::Find::name, 'global.graph');
						$global_graph_by_dir{ $File::Find::name } =
							-f $global_for_dir
							? $global_for_dir
							: $global_graph_by_dir{ $File::Find::dir };
					}

					if( $class->is_loadable_quad_file($_) ) {
						# Quads use the graph IRIs inside the file itself.
						$path_to_graph_file{ File::Spec->abs2rel( $_, $path  ) } = \ undef;
					} elsif( $class->is_loadable_file($_) ) {
						$path_to_graph_file{ File::Spec->abs2rel( $_, $path  ) } = do {
							my $graph_file = $class->map_single_file_to_graph_ld_dir( $_ )
								// $global_graph_by_dir{$File::Find::dir};
							defined $graph_file ? File::Spec->abs2rel( $graph_file, $path ) : undef;
						};
					}
				},
				follow   => 1,
				no_chdir => 1,
			}, $path, );

		\%path_to_graph_file;
	}

	sub load_single_file_sql($class, $file, $graph_iri = undef ) {
		my ($file_base, $file_dir) = ( basename( $file ), dirname( $file ) );
		# NOTE $file_base is a LIKE pattern. Might need to escape any /[\[%]/ ?
		my $sql = <<~SQL;
		ld_dir(@{[
				$class->sql_string($file_dir)
			]}, @{[
				$class->sql_string($file_base)
			]}, @{[
				defined $graph_iri
				? $class->sql_string($graph_iri)
				: $class->sql_null
			]}) ;
		SQL

		return $sql;
	}

	sub rdf_loader_sql($class, $sql_statements) {
		return <<~SQL;
		DELETE FROM DB.DBA.load_list;

		@{[ join "\n", @$sql_statements ]}

		SELECT * FROM DB.DBA.load_list;

		-- NOTE: log_enable = 2 disables triggers
		rdf_loader_run(log_enable=>2) ;
		SQL
	}

	sub can_run_isql($class) {
		my $bin = 'isql';
		die "Unable to find executable $bin" unless can_run($bin);
	}

	sub run_sql($class, $sql) {
		$class->can_run_isql;

		my ($fh, $sql_filename) = tempfile( SUFFIX => '.sql' );

		print $fh $sql;
		$fh->close;

		system( qw(isql), "exec=LOAD $sql_filename" ) == 0 or die "Could not run $sql_filename: $sql";
	}


=head1 SEE ALSO

=over 4

=item * L<Virtuoso: Bulk Loading RDF Source Files into one or more Graph IRIs|https://vos.openlinksw.com/owiki/wiki/VOS/VirtBulkRDFLoader>

=item * L<https://github.com/openlink/vos-docker-bulkload-example>

=item * L<https://community.openlinksw.com/t/how-to-bulk-load-data-into-a-virtuoso-docker-instance/3248>

=back

=cut

	if( $ENV{HARNESS_ACTIVE} ) {
		eval { Test2::V0->import; 1 } or die "Could not load Test2";
	}
	sub test {
		eval {
			require File::Temp;
			require File::Basename;
			require File::Spec;
			1;
		} or die "Could not load test modules";
		subtest( 'Corresponding graphs in directory' => sub {
			my $db = __PACKAGE__;

			my $dir = File::Temp::tempdir( CLEANUP => 1 );
			my @files = (
				map { File::Spec->catfile( $dir, @$_ ) } (
					[ 'example1.nt'              ],
					[ 'example2.nt.bz2'          ],
					[ 'example2.nt.graph'        ],
					[ 'example3.nt.gz'           ],
					[ 'global.graph'             ],
					[ 'subdir', 'example4.nt.gz' ],
					[ 'example5.nq.xz'           ],
				)
			);
			for my $file (@files) {
				my $file_dir = dirname($file);
				mkdir $file_dir or die unless -d $file_dir;
				open( my $fh, '>', $file );
			}

			my $path_to_graph = $db->map_path_to_graph_files_ld_dir_all( $dir );

			is($path_to_graph, hash(sub {
				field('example1.nt'           => 'global.graph'      );
				field('example2.nt.bz2'       => 'example2.nt.graph' );
				field('example3.nt.gz'        => 'global.graph'      );
				field('subdir/example4.nt.gz' => 'global.graph'      );
				field('example5.nq.xz'        => \ undef             );
				end();
			}), 'mapped from RDF paths to .graph files');
		});

		subtest( 'SQL generation' => sub {
			my $db = __PACKAGE__;

			like($db->load_single_file_sql( 'a/b.ttl' ), qr{
					\Qld_dir('a', 'b.ttl', NULL)\E
				}xs,
				'Load a/b.ttl with NULL graph');

			like($db->load_single_file_sql( 'a/b.ttl', 'http://example.org/' ), qr{
					\Qld_dir('a', 'b.ttl', 'http://example.org/')\E
				}xs,
				'Load a/b.ttl with predefined graph');
		});
	}
}

package Bio_Bricks::File::HDT {
	use strict;
	use warnings;
	use feature qw(signatures postderef);
	no warnings qw(experimental::signatures experimental::postderef);

	# CORE MODULES ONLY
	use File::Find;
	use IPC::Cmd qw(can_run run);

=head1 NAME

Bio_Bricks::File::HDT

=cut

	our $HDT_EXT_QR       = qr/\.hdt$/;

	our %COMPRESSION_TO_CMD = (
		'gzip'  => [ qw(gzip --best)  ],
		'bzip2' => [ qw(bzip2 --best) ],
	);

=head1 CLASS METHODS

=head2 is_hdt_file

Returns true if file is an C<.hdt> file by its extension.

=cut
	sub is_hdt_file($class, $file) {
		return !! ( -f $file && $file =~ $HDT_EXT_QR );
	}

=head2 find_hdt_files

Returns an C<ArrayRef> of all C<.hdt> files under path recursively.

=cut
	sub find_hdt_files($class, $path) {
		my @files;
		find( {
				wanted => sub {
					return unless $class->is_hdt_file($_);
					push @files, $File::Find::name;
				},
				follow   => 1,
				no_chdir => 1,
			}, $path, );

		\@files;
	}

	sub convert_to_ntriples($class, $input_file, $output_file, $compression = undef ) {
		# NOTE Based on testing, `hdt2rdf` gives the same
		# output N-Triple file across multiple runs, i.e. it is
		# a pure command.
		my @compression_cmd = exists $COMPRESSION_TO_CMD{$compression}
			? $COMPRESSION_TO_CMD{$compression}->@*
			: () ;
		die "Unknown compression $compression" if $compression && !@compression_cmd;

		for my $bin ( qw(hdt2rdf dd), ( @compression_cmd ? $compression_cmd[0] : () ) ) {
			die "Unable to find executable $bin" unless can_run($bin);
		}

		my( $success, $error_message, $full_buf, $stdout_buf, $stderr_buf ) =
			run( command => [
				# to N-Triples on STDOUT
				# Format flag:
				# -f [ntriples, n3, turtle]
				qw( hdt2rdf -f ntriples), $input_file, '-',

				# compress if enabled
				( @compression_cmd
				? ( '|', @compression_cmd )
				: ()
				),

				# pipe out to file
				'|',
				qw( dd ),  "of=$output_file"

			], verbose => 0 );

		die "Could not convert $input_file to $output_file: $full_buf" unless $success;
	}

	if( $ENV{HARNESS_ACTIVE} ) {
		eval { Test2::V0->import; 1 } or die "Could not load Test2";
	}
	sub test {
		eval {
			require File::Temp;
			require File::Basename;
			require File::Spec;
			1;
		} or die "Could not load test modules";
		subtest( 'Find HDT files' => sub {
			my $hdt = __PACKAGE__;

			my $dir = File::Temp::tempdir( CLEANUP => 1 );
			my @files = (
				map { File::Spec->catfile( $dir, @$_ ) } (
					[ 'example1.hdt'           ],
					[ 'example2.hdt.nt'        ],
					[ 'example3.hdt.gz'        ],
					[ 'example3.ttl'           ],
					[ 'subdir', 'example4.hdt' ],
				)
			);
			for my $file (@files) {
				my $file_dir = File::Basename::dirname($file);
				mkdir $file_dir or die unless -d $file_dir;
				open( my $fh, '>', $file );
			}

			my @hdt_files = map { File::Spec->abs2rel($_, $dir) } $hdt->find_hdt_files( $dir )->@*;

			is(\@hdt_files, bag(sub {
				item('example1.hdt');
				item('subdir/example4.hdt');
				end();
			}), 'found .hdt files');
		});


		subtest( 'Convert HDT to N-Triples' => sub {
			my $hdt = __PACKAGE__;

			my $dir = File::Temp::tempdir( CLEANUP => 1 );
			my $ttl_file = File::Spec->catfile( $dir, 'test.ttl' );
			my $hdt_file = File::Spec->catfile( $dir, 'test.hdt' );
			my $nt_file  = File::Spec->catfile( $dir, 'test.nt' );
			my $nt_bz2_file  = File::Spec->catfile( $dir, 'test.nt.bz2' );

			open( my $ttl_fh, '>', $ttl_file );
			print $ttl_fh <<~'EOF';
			@base <http://example.org/> .
			@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
			@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
			@prefix foaf: <http://xmlns.com/foaf/0.1/> .
			@prefix rel: <http://www.perceive.net/schemas/relationship/> .

			<#green-goblin>
				rel:enemyOf <#spiderman> ;
				a foaf:Person ;
				.
			EOF
			$ttl_fh->close;

			0 == system( qw(rdf2hdt), $ttl_file, $hdt_file ) or die "Could not create .hdt file";

			$hdt->convert_to_ntriples( $hdt_file, $nt_file );

			$hdt->convert_to_ntriples( $hdt_file, $nt_bz2_file, 'bzip2' );

			open my $cat_pipe, '-|', qw(cat), $nt_file;
			my $nt_file_contents = do { local $/; <$cat_pipe> };

			my $triple_string = q{<#green-goblin> <http://www.perceive.net/schemas/relationship/enemyOf> <#spiderman> .};
			like($nt_file_contents, qr{
				^ \Q$triple_string\E $
			}xm, '.nt has triple');

			open my $bzcat_pipe, '-|', qw(bzcat), $nt_bz2_file;
			my $nt_bz2_file_contents = do { local $/; <$bzcat_pipe> };

			is( $nt_file_contents, $nt_bz2_file_contents, 'uncompressed and compressed have same contents');
		});
	}
}

package Bio_Bricks::Process::VirtuosoLoader {
	use strict;
	use warnings;
	use feature qw(say signatures postderef);
	no warnings qw(experimental::signatures experimental::postderef);

	# CORE MODULES ONLY
	use File::Find;
	use File::Basename qw(basename dirname);
	use File::Temp qw(tempfile);
	use File::Copy qw(copy move);
	use CPAN::Meta::YAML;

	# Non-core
	use Parallel::ForkManager;

	sub _log(@msg) {
		say STDERR @msg;
	}

	sub load_spec($self, $spec) {
		my @files;
		my $name = $spec->{name} // die "Missing 'name' key in spec";
		die "Missing 'path' key in spec for $name" unless exists $spec->{path};
		my $spec_path = File::Spec->catfile( $self->{dir}, $spec->{path} );
		die "Path $spec_path does not exist" unless -e $spec_path;
		my $spec_graph_iri = do {
			my $spec_graph_file = File::Spec->catfile(
				$self->{dir},
				'graph-meta',
				"${name}.graph"
			);

			die "Graph file $spec_graph_file for $name is not readable"
				unless -r $spec_graph_file;

			open my $graph_file_fh, '<', $spec_graph_file;
			chomp( my $graph_iri = do { local $/; <$graph_file_fh> } );

			$graph_iri;
		};
		find( {
				wanted => sub {
					return unless Bio_Bricks::DB::Virtuoso->is_loadable_file($_)
						|| Bio_Bricks::File::HDT->is_hdt_file($_);

					return if /\Q.hdt.nt\E(?:\.(?:gz|bz2|xz))?$/; # converted already
					push @files, $File::Find::name;
				},
				follow   => 1,
				no_chdir => 1,
			}, $spec_path, );

		my @sql_ld_dirs;
		# This is Docker. It has nproc.
		chomp(my $ncpus = `nproc`);
		my $pm = Parallel::ForkManager->new($ncpus);
		$pm->run_on_start( sub {
			my ($pid, $ident)=@_;
			print "** $ident started, pid: $pid\n";
		});
		$pm->run_on_finish( sub {
			my ($pid, $exit_code, $ident,
				$exit_signal, $core_dump, $data_structure_reference) = @_;

			die "** $ident failed ".
				"with PID $pid and exit code: $exit_code"
				if $exit_code;

			if( defined $data_structure_reference ) {
				if( ! exists $data_structure_reference->{converted}
					|| $data_structure_reference->{converted} ) {
					push @sql_ld_dirs,
						Bio_Bricks::DB::Virtuoso->load_single_file_sql(
							$data_structure_reference->{file},
							$spec_graph_iri);
				}
			}
		});
		DATA_LOOP:
		for my $file (@files) {
			_log "$file: Processing...";
			my $pid = $pm->start("process($file)") and next DATA_LOOP;
			if( Bio_Bricks::File::HDT->is_hdt_file($file) ) {
				my $hdt_file = $file;
				my $compression_type = 'bzip2';
				my $suffix = '.nt.bz2'; # append .nt.bz2 to file
				my $nt_file  = "${hdt_file}${suffix}";

				my $ran_conversion = 0;
				if( ! -f $nt_file || -M $hdt_file < -M $nt_file ) {
					_log "$file: Converting from $hdt_file to $nt_file";

					my (undef, $nt_file_temp) = tempfile( OPEN => 0, DIR => $self->{tmpdir},
						SUFFIX => ".tmp.hdt${suffix}" );
					eval {
						Bio_Bricks::File::HDT->convert_to_ntriples(
							$hdt_file => $nt_file_temp,
							$compression_type );
						1;
					} or do {
						my $err = $@;
						unlink $nt_file_temp;
						die "Could not convert $hdt_file to $nt_file: $@";
					};

					move( $nt_file_temp, $nt_file );
					$ran_conversion = 1;
				} else {
					_log "$file: Skipping conversion from $hdt_file to $nt_file: $nt_file exists and is newer than $hdt_file";
				}

				$pm->finish(0, {
					file => $nt_file ,
					hdt_file => $hdt_file,
					converted => !! $ran_conversion,
				} );
			} else {
				# any other type of RDF file
				$pm->finish(0, {
					file => $file,
				} );
			}

		}
		$pm->wait_all_children;

		my $sql = Bio_Bricks::DB::Virtuoso->rdf_loader_sql( \@sql_ld_dirs );
		## no critic: InputOutput::ProhibitInteractiveTest
		#if( -t ) {
		#        say $sql;
		#} else {
			say STDERR $sql;
			Bio_Bricks::DB::Virtuoso->run_sql( $sql );
		#}
	}

	sub load_all($self) {
		for my $spec ($self->{graphs}->@*) {
			$self->load_spec($spec);
		}
	}

	sub new($class, %args) {
		my $self = {};
		$self->{dir} = delete $args{dir} // die "Missing 'dir' parameter";

		my $tmpdir = File::Spec->catfile( $self->{dir}, "_tmp" );
		if( ! -e $tmpdir ) {
			mkdir $tmpdir or die "Could not create $tmpdir: $!";
		} else {
			die "Path $tmpdir already exists and is not a directory" unless -d $tmpdir;
		}
		$self->{tmpdir} = $tmpdir;

		$self->{graphs} = do {
			open my $graphs_yml_fh, '<', File::Spec->catfile($self->{dir}, 'graphs.yaml')
				or die "Could not open graphs.yaml: $!";

			my $graphs_yml = do { local $/; <$graphs_yml_fh> };
			my $graphs_data = CPAN::Meta::YAML->read_string($graphs_yml)
				  or die CPAN::Meta::YAML->errstr;

			$graphs_data->[0];
		};

		return bless $self, $class;
	}

	sub main {
		my $data_toplevel_dir = shift @ARGV;

		my $loader = __PACKAGE__->new( dir => $data_toplevel_dir );

		$loader->load_all;
	}
}

sub test {
	subtest('Bio_Bricks::DB::Virtuoso' => \&Bio_Bricks::DB::Virtuoso::test);
	subtest('Bio_Bricks::File::HDT'    => \&Bio_Bricks::File::HDT::test);
	done_testing();
}

if( $ENV{HARNESS_ACTIVE} ) {
	test;
	exit;
}

Bio_Bricks::Process::VirtuosoLoader::main unless caller();
